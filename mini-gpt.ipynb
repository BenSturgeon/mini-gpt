{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2213b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 24 16:44:54 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1060         Off| 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   69C    P8                7W /  N/A|     63MiB /  6144MiB |     31%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       558      G   /usr/lib/Xorg                                61MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c13814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e83d1b8",
   "metadata": {},
   "source": [
    "\n",
    "# Plan of action\n",
    "\n",
    "## Steps\n",
    "* Download the data\n",
    "* Tokenizer\n",
    "* Batch creator\n",
    "* Create a basic forward pass\n",
    "* self attention layer\n",
    "* Create a training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb688ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# download tiny shakespeare\n",
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d2a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the file directly to a variable\n",
    "text = urllib.request.urlopen(url).read().decode('utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a9bf2e3",
   "metadata": {},
   "source": [
    "## Create a tokenizer at the character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b51312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "[25, 57, 57, 30, 31, 25, 35, 37, 35]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(text))\n",
    "vocab_size = len(tokens)\n",
    "print(vocab_size)\n",
    "\n",
    "# Create an encoder decoder for our tokens to turn them into numbers and back\n",
    "encoder_decoder = {token: i for i, token in enumerate(tokens)}\n",
    "decoder_encoder = {i: token for i, token in enumerate(tokens)}\n",
    "\n",
    "encode = lambda x: [encoder_decoder[i] for i in x]\n",
    "decode = lambda x: \"\".join([decoder_encoder[i] for i in x])\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15488944",
   "metadata": {},
   "source": [
    "## Creating our dataset\n",
    "We split the data into training and validation with 90/10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d8fd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "split_val = int(len(data) * 0.9)\n",
    "train_data = data[:split_val]\n",
    "val_data = data[split_val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34883c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d91be20",
   "metadata": {},
   "source": [
    "### Turning our data into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a946a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[57, 53, 30,  8, 63, 63, 45, 30],\n",
      "        [54,  5, 36, 63, 43, 30, 53, 25],\n",
      "        [37, 30,  6, 63, 43, 37, 30,  8],\n",
      "        [30, 14, 30, 16, 37, 27,  0, 35]])\n",
      "\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53, 30,  8, 63, 63, 45, 30, 35],\n",
      "        [ 5, 36, 63, 43, 30, 53, 25, 27],\n",
      "        [30,  6, 63, 43, 37, 30,  8, 37],\n",
      "        [14, 30, 16, 37, 27,  0, 35, 30]])\n",
      "Input is tensor([57]) and target is 53\n",
      "Input is tensor([57, 53]) and target is 30\n",
      "Input is tensor([57, 53, 30]) and target is 8\n",
      "Input is tensor([57, 53, 30,  8]) and target is 63\n",
      "Input is tensor([57, 53, 30,  8, 63]) and target is 63\n",
      "Input is tensor([57, 53, 30,  8, 63, 63]) and target is 45\n",
      "Input is tensor([57, 53, 30,  8, 63, 63, 45]) and target is 30\n",
      "Input is tensor([57, 53, 30,  8, 63, 63, 45, 30]) and target is 35\n",
      "Input is tensor([54]) and target is 5\n",
      "Input is tensor([54,  5]) and target is 36\n",
      "Input is tensor([54,  5, 36]) and target is 63\n",
      "Input is tensor([54,  5, 36, 63]) and target is 43\n",
      "Input is tensor([54,  5, 36, 63, 43]) and target is 30\n",
      "Input is tensor([54,  5, 36, 63, 43, 30]) and target is 53\n",
      "Input is tensor([54,  5, 36, 63, 43, 30, 53]) and target is 25\n",
      "Input is tensor([54,  5, 36, 63, 43, 30, 53, 25]) and target is 27\n",
      "Input is tensor([37]) and target is 30\n",
      "Input is tensor([37, 30]) and target is 6\n",
      "Input is tensor([37, 30,  6]) and target is 63\n",
      "Input is tensor([37, 30,  6, 63]) and target is 43\n",
      "Input is tensor([37, 30,  6, 63, 43]) and target is 37\n",
      "Input is tensor([37, 30,  6, 63, 43, 37]) and target is 30\n",
      "Input is tensor([37, 30,  6, 63, 43, 37, 30]) and target is 8\n",
      "Input is tensor([37, 30,  6, 63, 43, 37, 30,  8]) and target is 37\n",
      "Input is tensor([30]) and target is 14\n",
      "Input is tensor([30, 14]) and target is 30\n",
      "Input is tensor([30, 14, 30]) and target is 16\n",
      "Input is tensor([30, 14, 30, 16]) and target is 37\n",
      "Input is tensor([30, 14, 30, 16, 37]) and target is 27\n",
      "Input is tensor([30, 14, 30, 16, 37, 27]) and target is 0\n",
      "Input is tensor([30, 14, 30, 16, 37, 27,  0]) and target is 35\n",
      "Input is tensor([30, 14, 30, 16, 37, 27,  0, 35]) and target is 30\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = val_data\n",
    "    batch_start_indexes = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in batch_start_indexes])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in batch_start_indexes])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "\n",
    "print(f\"\"\"\n",
    "inputs:\n",
    "{xb.shape}\n",
    "{xb}\n",
    "\n",
    "targets:\n",
    "{yb.shape}\n",
    "{yb}\"\"\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        x = xb[b][:t+1]\n",
    "        y = yb[b][t]\n",
    "        print(f\"Input is {x} and target is {y}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "394512b0",
   "metadata": {},
   "source": [
    "### Creating our model\n",
    "Our goal is to create a simple bigram model using pytorch nn.Module as our basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b3f96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.7022, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        \n",
    "        else:\n",
    "            # Where \n",
    "            # B = batch_size = 4\n",
    "            # T = time = 8\n",
    "            # C = channel = 65 = vocab_size\n",
    "            #  We change the shapes of our logits to get them in the shape needed to use pytorch's cross_entropy function\n",
    "\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "        return logits\n",
    "    \n",
    "    def generate(self, x_input, max_new_tokens):\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(x_input) # we're not using loss, as we're generating\n",
    "\n",
    "            next_token = logits[:, -1,:]\n",
    "\n",
    "            probabilities = F.softmax(next_token, dim=-1)\n",
    "\n",
    "            top_answer = torch.multinomial(probabilities, num_samples=1)\n",
    "\n",
    "            x_input = torch.cat((x_input, top_answer), dim=1) # B, T+1. Appending to 1st dimension which is the time dimension\n",
    "\n",
    "        return x_input\n",
    "        \n",
    "\n",
    "\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = model(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss) # Loss is very high at this point, 4.6 \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtjlUKnCe!?YsD.;DfxdaDJP\n",
      " vsfU'GwiJ.LDDkN?;i$h:TD- tKoNsgUcPiSriSPAnTyWu-!Pk;dVzAVwi3ReegaEPfZkbMhiS&\n"
     ]
    }
   ],
   "source": [
    "x_input = torch.zeros((1,1),dtype=torch.long )\n",
    "print(decode(model.generate(x_input, max_new_tokens=100)[0].tolist())) \n",
    "# Output is garbage, as we have not begun any training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eff0e553",
   "metadata": {},
   "source": [
    "### Creating our backward pass\n",
    "In this step we create an optimizer and demonstrate a basic gradient descent loop. \n",
    "\n",
    "So far our model is just an embedding table with the dimensions of vocab_size * vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7eeaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85289c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4738, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for i in range(5000):\n",
    "    xb, yb = get_batch(batch_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f8a90bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medghed mik;\n",
      "Gren; cer Fpr itoonFuckigas Wb, oO:\n",
      "\n",
      "ARUJ.\n",
      "I pun:\n",
      "BAno day:\n",
      "KA:\n",
      "HGrackig foJIO:\n",
      "Youw\n",
      "\n",
      "s \n"
     ]
    }
   ],
   "source": [
    "x_input = torch.zeros((1,1),dtype=torch.long )\n",
    "print(decode(model.generate(x_input, max_new_tokens=100)[0].tolist())) \n",
    "# Output should look somewhat more sensible, and it does! \n",
    "# This is because the tokens have some idea about what should come next just through information encoded in their own embeddings.\n",
    "# However, we observe a plateau in loss of around 2.3. We'll need to implement new tricks to break through."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "710d344c",
   "metadata": {},
   "source": [
    "### Adding self-attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37da8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "--\n",
      "c=\n",
      "tensor([[5.0000, 7.0000],\n",
      "        [3.5000, 3.5000],\n",
      "        [4.0000, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a/torch.sum(a,1,keepdim=True)\n",
    "b = torch.randint(0,10, (3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b58c7f48",
   "metadata": {},
   "source": [
    "The purpose of the following example is to demonstrate the simplest implementation of how tokens can communicate with each other.\n",
    "\n",
    "In this case we just average out all the values of the previous token's channels, which is obviously very lossy, but this is simply illustrative.\n",
    "\n",
    "We will have a way to add all that back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4840e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True]) tensor([True, True])\n"
     ]
    }
   ],
   "source": [
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape\n",
    "\n",
    "\n",
    "# Here we use a bag of words (bow) to illustrate our averaging example\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, 0)\n",
    "\n",
    "# The purpose of this is to show that the rows of xbow are equal to the average of the values in all previous rows of x\n",
    "\n",
    "print(xbow[0][1] == torch.mean(x[0][:2],0), xbow[0][2] == torch.mean(x[0][:3],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab18a93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T,T))\n",
    "print(wei.sum(1, keepdim=True))\n",
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "print(wei)\n",
    "xbow2 = wei@x\n",
    "torch.allclose(xbow,xbow2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1852d319",
   "metadata": {},
   "source": [
    "Our next step is to demonstrate that we can do the above using softmax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2df0924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "print(wei)\n",
    "wei = wei.masked_fill(tril==0, float('-inf')) \n",
    "print(wei)\n",
    "wei = torch.softmax(wei,dim=1)\n",
    "print(wei)\n",
    "xbow3 = wei@x\n",
    "torch.allclose(xbow3,xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eee6bff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-inf)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(float('-inf'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcb8938b",
   "metadata": {},
   "source": [
    "To determine the attention of words (more exactly tokens) we use ‘queries’, ‘keys’ and ‘values’.\n",
    "\n",
    "All of them are presented in vectors. \n",
    "\n",
    "Keys activate depending on the strength of closeness with the query vector as determined by dot product.\n",
    "\n",
    "Keys are an encoded representation for values, in simple cases they can be the same. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83a8bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3116, -0.2300,  0.0999,  0.3821, -0.1887,  0.3470,  0.1903, -0.0801],\n",
      "        [-0.5893, -0.2927,  0.0184,  0.5972, -0.3858,  0.1841, -0.0098,  0.0517],\n",
      "        [-0.1808, -0.2229,  0.0135, -0.0674, -0.1740, -0.2528,  0.0132, -0.1688],\n",
      "        [ 0.1385, -0.1417, -0.0595, -0.1502, -0.0990, -0.2069, -0.2285, -0.1814],\n",
      "        [-0.2221,  0.0033, -0.1393, -0.2334,  0.3600,  0.1527,  0.0657,  0.1637],\n",
      "        [-0.0553,  0.4270, -0.0195, -0.1755,  0.5913, -0.4460,  0.2508,  0.2156],\n",
      "        [ 0.1923,  0.3474, -0.0463, -0.0558,  0.1077,  0.2230, -0.0969,  0.1423],\n",
      "        [-0.3190, -0.0729, -0.1468,  0.1043, -0.1412, -0.1035,  0.1137,  0.1114]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.3116,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.5893, -0.2927,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.1808, -0.2229,  0.0135,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.1385, -0.1417, -0.0595, -0.1502,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.2221,  0.0033, -0.1393, -0.2334,  0.3600,    -inf,    -inf,    -inf],\n",
      "        [-0.0553,  0.4270, -0.0195, -0.1755,  0.5913, -0.4460,    -inf,    -inf],\n",
      "        [ 0.1923,  0.3474, -0.0463, -0.0558,  0.1077,  0.2230, -0.0969,    -inf],\n",
      "        [-0.3190, -0.0729, -0.1468,  0.1043, -0.1412, -0.1035,  0.1137,  0.1114]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4264, 0.5736, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3151, 0.3022, 0.3827, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3007, 0.2272, 0.2467, 0.2253, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1635, 0.2048, 0.1776, 0.1616, 0.2926, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1403, 0.2272, 0.1454, 0.1244, 0.2678, 0.0949, 0.0000, 0.0000],\n",
      "        [0.1554, 0.1815, 0.1224, 0.1213, 0.1428, 0.1603, 0.1164, 0.0000],\n",
      "        [0.0952, 0.1217, 0.1130, 0.1453, 0.1137, 0.1180, 0.1467, 0.1464]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([4, 8, 16])\n",
      "torch.Size([4, 8, 16])\n",
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "#Attention head\n",
    "head_size = 16\n",
    "key = nn.Linear(C,head_size,  bias=False)\n",
    "query = nn.Linear(C,head_size, bias=False)\n",
    "value = nn.Linear(C,head_size, bias=False)\n",
    "k = key(x)      # B,T,16\n",
    "q = query(x)    # B,T,16\n",
    "\n",
    "wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "print(wei[0])\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "print(wei[0])\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(wei[0])\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "print(v.shape)\n",
    "print(out.shape)\n",
    "# print(wei[0])\n",
    "# print(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3efd136",
   "metadata": {},
   "source": [
    "### Code explanations of the above:\n",
    "\n",
    "wei = q @ k.transpose(-2,-1) * C**-0.5\n",
    "\n",
    "The tranpose is used so we end up with a matrix of B,T,T:\n",
    "\n",
    "(B,T,16) @ (B,16,T) ---> B, T, T: our desired shape\n",
    "\n",
    "\n",
    "This lets us do batch matrix multiplication on our tril matrix which is size(16,16)\n",
    "\n",
    "\n",
    "We apply the normalisation of  C**-0.5 to our wei variable as a normalisation step. We divide by the square route of our head size so that we avoid peaks that are too high in our initial weights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff044d69",
   "metadata": {},
   "source": [
    "### Adding our layernorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2197ccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # (used to be BatchNorm1d)\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) # batch mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
